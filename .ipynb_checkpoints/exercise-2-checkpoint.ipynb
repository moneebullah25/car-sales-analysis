{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1296a9d3-5dba-4c3c-95bf-351631207c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5fa432e-4e9b-4682-8368-4ae67aff15f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom dataset\n",
    "class CustomFlowerDataset(ImageFolder):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        super(CustomFlowerDataset, self).__init__(root=root_dir, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "771e8fee-ed7c-4dbb-baed-18d76871d7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 28 * 28, 128)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.pool3(self.relu3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu4(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1d82537-c7d7-4152-86ee-101d75d9e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a01f5329-b69f-4ca1-89b0-39c3266697b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the custom dataset\n",
    "flower_dataset = CustomFlowerDataset(root_dir='flower_photos', transform=transform)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "train_size = int(0.8 * len(flower_dataset))\n",
    "test_size = len(flower_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(flower_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "485a2a64-b242-47b3-a218-ebce4354bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68b1e081-32fa-4fab-b55a-ecd19d47f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss criterion, and optimizer\n",
    "model = SimpleCNN(num_classes=len(flower_dataset.classes)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1f6b429-d8bc-4534-8033-5796bed59d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.1273\n",
      "Epoch [2/5], Loss: 0.0654\n",
      "Epoch [3/5], Loss: 0.0319\n",
      "Epoch [4/5], Loss: 0.0105\n",
      "Epoch [5/5], Loss: 0.0151\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "print('Training finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8413f81a-f406-45b4-8b88-9deeee6fc04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 60.35%\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91741b55-449e-401f-b0dd-a295c53e6470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
